{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import librosa\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-26T19:22:41.104188Z","iopub.execute_input":"2022-06-26T19:22:41.104597Z","iopub.status.idle":"2022-06-26T19:22:53.568145Z","shell.execute_reply.started":"2022-06-26T19:22:41.104511Z","shell.execute_reply":"2022-06-26T19:22:53.566653Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"directory = \"\" #The directory containing the sound files","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:22:53.570286Z","iopub.execute_input":"2022-06-26T19:22:53.570961Z","iopub.status.idle":"2022-06-26T19:22:53.576759Z","shell.execute_reply.started":"2022-06-26T19:22:53.570922Z","shell.execute_reply":"2022-06-26T19:22:53.575526Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\nsample_rate = 8000\n\ndef load_audio_file(audio_file_path):\n    audio_segment, _ = librosa.load(audio_file_path, sr=sample_rate)\n    return audio_segment\n\ndef fix_audio_segment_to_10_seconds(audio_segment):\n    target_len = 10 * sample_rate\n    audio_segment = np.concatenate([audio_segment]*2, axis=0)\n    audio_segment = audio_segment[0:target_len]\n    \n    return audio_segment\n\ndef spectrogram(audio_segment):\n    image_width = 500\n    image_height = 128\n    # Compute Mel-scaled spectrogram image\n    hl = audio_segment.shape[0] // image_width\n    spec = librosa.feature.melspectrogram(audio_segment,\n                                     n_mels=image_height, \n                                     hop_length=int(hl))\n\n    # Logarithmic amplitudes\n    image = librosa.core.power_to_db(spec)\n\n    # Convert to np matrix\n    image_np = np.asmatrix(image)\n\n    # Normalize and scale\n    image_np_scaled_temp = (image_np - np.min(image_np))\n    \n    image_np_scaled = image_np_scaled_temp / np.max(image_np_scaled_temp)\n\n    return image_np_scaled[::-1, :image_width]\n\ndef to_integer(image_float):\n    # range (0,1) -> (0,255)\n    image_float_255 = image_float * 255.0\n    \n    # Convert to uint8 in range [0:255]\n    image_int = image_float_255.astype(np.uint8)\n    \n    return image_int\n\n\n\ndef processWav(f):\n    if os.path.isdir(\"./out\") == False:\n        os.mkdir(\"./out\")\n    \n    audio = fix_audio_segment_to_10_seconds(load_audio_file(f\"{directory}/{f}\"))\n    f = os.path.basename(os.path.basename(f))\n    img = to_integer(spectrogram(audio))\n    os.system('clear')\n    plt.imsave(f\"./out/{f[:-4]}.png\", img, vmin=0, vmax=255)\n    img = Image.open(f\"./out/{f[:-4]}.png\").convert('L')\n    img.save(f\"./out/{f[:-4]}.png\")\n    \n    return f\"./out/{f[:-4]}.png\"","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:22:53.578606Z","iopub.execute_input":"2022-06-26T19:22:53.579957Z","iopub.status.idle":"2022-06-26T19:22:53.655107Z","shell.execute_reply.started":"2022-06-26T19:22:53.579904Z","shell.execute_reply":"2022-06-26T19:22:53.653791Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!wget ./model.h5 https://github.com/algosup/2022-Project-Artificial-Intelligence-Group-B/blob/main/model.h5?raw=true\nmodel = load_model(\"./model.h5?raw=true\")","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:22:53.659332Z","iopub.execute_input":"2022-06-26T19:22:53.659770Z","iopub.status.idle":"2022-06-26T19:22:55.765649Z","shell.execute_reply.started":"2022-06-26T19:22:53.659734Z","shell.execute_reply":"2022-06-26T19:22:55.764114Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"for filename in os.listdir(directory):\n    f = os.path.join(directory, filename)\n    path = processWav(filename)\n    \n    img = Image.open(path)\n    img = np.array(img)\n    \n    img = img/255\n    img = img.reshape(1, 128, 500, 1)\n    \n    prediction = model.predict(img)\n    if(prediction[0][0] < 0.5):\n        print(f\"{path[6:-4]} is French\")\n    else:\n        print(f\"{path[6:-4]} is English\")","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:22:55.767476Z","iopub.execute_input":"2022-06-26T19:22:55.767835Z","iopub.status.idle":"2022-06-26T19:23:02.236705Z","shell.execute_reply.started":"2022-06-26T19:22:55.767798Z","shell.execute_reply":"2022-06-26T19:23:02.235257Z"},"trusted":true},"execution_count":5,"outputs":[]}]}