{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be kept to False\n",
    "# It will generate audio and spectrogram files for debugging purposes\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpiozero import LED\n",
    "from io import BytesIO\n",
    "from librosa import feature, load as load_audio, power_to_db\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.io.wavfile import write\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from sounddevice import InputStream # Takes a long time to import (~10s on our Raspberry)\n",
    "from tensorflow.keras.models import load_model\n",
    "from time import sleep, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the constants and global values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug settings\n",
    "LANGS = [\"EN\", \"FR\"]\n",
    "DEBUG_AUDIO_PATH = \"/home/groupb/Documents/result.wav\"\n",
    "DEBUG_SPECTROGRAM_PATH = \"/home/groupb/Documents/outputs/{}.png\"\n",
    "debug_wav = np.array([])\n",
    "\n",
    "# Audio settings\n",
    "CHANNEL_NB = 1\n",
    "CHUNK_SIZE = 1024  # Record in chunks of 1024 samples\n",
    "DURATION = 10 # Duration of recording for the prediction\n",
    "REC_SAMPLE_RATE = 44100\n",
    "\n",
    "# Spectrogram and model\n",
    "IMAGE_SIZE = 500, 128\n",
    "SPEC_SAMPLE_RATE = 8000\n",
    "MODEL_PATH = \"/home/groupb/Documents/model.h5\"\n",
    "img_index = 0\n",
    "\n",
    "# LEDs configuration (from lowest to highest probability)\n",
    "LEDS = [\n",
    "    LED(2), LED(6), LED(5), # French\n",
    "    LED(4), LED(3), LED(13), # English\n",
    "    LED(19) # Unknown\n",
    "]\n",
    "last_led = None\n",
    "\n",
    "# LED selection function\n",
    "MIN_CERTAINTY = 0.5 # Below that percentage, consider it unkown\n",
    "\n",
    "def choose_led(index, prediction):\n",
    "    value = prediction[index] # value ∈ [0, 1]\n",
    "    if value < MIN_CERTAINTY:\n",
    "        raise ValueError(f\"Prediction {value} is lower than the required probability {MIN_CERTAINTY}\")\n",
    "\n",
    "    # Custom LERP from [MIN_CERTAINTY, 1] to [0 .. size[\n",
    "    size = len(LEDS)\n",
    "    norm = (1 - value) / (1 - MIN_CERTAINTY) # norm ∈ [0, 1]\n",
    "    i = size - floor(norm * size) # i ∈ [0 .. size[\n",
    "    return i\n",
    "\n",
    "# Selenium configuration\n",
    "sele_colors = [\n",
    "    'red', # FR\n",
    "    'rgb(0, 165, 0)', 'yellowgreen', 'yellow', 'orange', # EN\n",
    "    'rgb(150, 150, 246)' # Unknown\n",
    "]\n",
    "sele_text = [\n",
    "    'French', # FR\n",
    "    'Great English', 'Good English', 'Understandable English', 'Bad English', # EN\n",
    "    'Unknown'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://google.com\");\n",
    "f = open(\"/home/groupb/Documents/serv/index.html\", \"r\")\n",
    "webElement = driver.find_element(by=By.XPATH, value='html/body');\n",
    "script = \"arguments[0].innerHTML=`\"+f.read()+\"`\"\n",
    "driver.execute_script(script, webElement);\n",
    "webElement = driver.find_element(by=By.XPATH, value='//*[@id=\"Result\"]')\n",
    "webElementtxt = driver.find_element(by=By.XPATH, value='//*[@id=\"Result\"]/h1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(duration):\n",
    "    \"\"\"\n",
    "    Format time in seconds to string.\n",
    "    \"\"\"\n",
    "    minutes, seconds = divmod(duration, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
    "\n",
    "\n",
    "\n",
    "def format_prediction(prediction):\n",
    "    return \"\\t\".join(\n",
    "        f\"{lang}: {prob}\"\n",
    "        for lang, prob in zip(LANGS, prediction)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def get_prediction_from_audio_file(filepath, model):\n",
    "    audio_buffer, _ = load_audio(filepath, sr=REC_SAMPLE_RATE)\n",
    "    spec = get_spectrogram(audio_buffer, SPEC_SAMPLE_RATE, img_size=IMAGE_SIZE)\n",
    "    img = spectrogram_to_grayscale(spec) / 255 # Converting because colors are unnecessary\n",
    "    prediction = model.predict(img.reshape(1, 128, 500, 1))[0]\n",
    "    print(filepath, \":\")\n",
    "    activate_leds(prediction)\n",
    "\n",
    "\n",
    "\n",
    "def cleanup(audio_path=\"\", image_path=\"\"):\n",
    "    \"\"\"\n",
    "    Clean up temporary files and connections.\n",
    "    \"\"\"\n",
    "    if DEBUG and os.path.exists(audio_path):\n",
    "        os.remove(audio_path)\n",
    "    if DEBUG and os.path.exists(image_path):\n",
    "        os.remove(image_path)\n",
    "    for led in LEDS:\n",
    "        led.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_audio_buffer(indata, frames, time, status):\n",
    "    \"\"\"\n",
    "    Process audio_buffer data into a spectrogram.\n",
    "\n",
    "    Callback for sd.InputStream.\n",
    "    \"\"\"\n",
    "    global audio_buffer, debug_wav\n",
    "    if DEBUG:\n",
    "        debug_wav = np.append(debug_wav, indata.copy())\n",
    "    audio_buffer = np.roll(audio_buffer, -frames)\n",
    "    audio_buffer[-frames:] = indata.reshape(-1,)\n",
    "\n",
    "\n",
    "\n",
    "def get_spectrogram(audio, sample_rate, img_size):\n",
    "    \"\"\"\n",
    "    Get image spectrogram from audio.\n",
    "\n",
    "    Callback for the sounddevice library.\n",
    "    \"\"\"\n",
    "    #audio = np.where(np.isnan(audio), 0, audio)\n",
    "    width, height = img_size\n",
    "    try:\n",
    "        spectrogram = feature.melspectrogram(y=audio, sr=sample_rate, hop_length=len(audio) // width, n_mels=height)\n",
    "        matrix = power_to_db(spectrogram)[::-1, :width]\n",
    "        return matrix\n",
    "\n",
    "    except RuntimeWarning:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "def spectrogram_to_grayscale(spectrogram):\n",
    "    \"\"\"\n",
    "    Process spectrogram into a gray-scale array.\n",
    "    \"\"\"\n",
    "    global img_index  # Debug\n",
    "    with BytesIO() as buffer:\n",
    "        plt.imsave(buffer, spectrogram, cmap=\"gray\")\n",
    "        buffer.seek(0)\n",
    "        img = Image.open(buffer).convert(\"L\")\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def get_prediction(audio, model):\n",
    "    spec = get_spectrogram(audio, SPEC_SAMPLE_RATE, img_size=IMAGE_SIZE)\n",
    "    spec = spectrogram_to_grayscale(spec) # Converting because colors are unnecessary\n",
    "    spec = spec.reshape(1, *spec.shape[:2], 1) / 255 # Reshape and normalize\n",
    "\n",
    "    predictions = model.predict(spec)\n",
    "    # The prediction is a list of lists of probabilities.\n",
    "    # The matching labels are [EN, FR] by default, can be changed in LANGS\n",
    "\n",
    "    return predictions[0]\n",
    "\n",
    "\n",
    "\n",
    "def activate_leds(prediction):\n",
    "    global last_led\n",
    "\n",
    "    val = np.max(prediction).round(decimals=2)\n",
    "    highest_probability_index = 0\n",
    "    arr_en=False\n",
    "\n",
    "    if np.argmax(prediction) == 0:\n",
    "        arr_en=True\n",
    "        highest_probability_index += 1\n",
    "    print(LANGS[np.argmax(prediction)] + \"  :  \" + str(val))\n",
    "\n",
    "    if val > .90:\n",
    "        highest_probability_index += 0\n",
    "    elif val > .80:\n",
    "        highest_probability_index += 1\n",
    "    elif val > .70:\n",
    "        highest_probability_index += 2\n",
    "    elif val > .60:\n",
    "        highest_probability_index += 3\n",
    "    else:\n",
    "        highest_probability_index = -1\n",
    "\n",
    "    if last_led is not None:\n",
    "        last_led.off()\n",
    "    if not arr_en and val < .70:\n",
    "        highest_probability_index = -1\n",
    "    elif not arr_en and val > .70:\n",
    "        highest_probability_index = 0\n",
    "\n",
    "    script = \"arguments[0].style.backgroundColor = '\" + sele_colors[highest_probability_index] + \"'\"\n",
    "    driver.execute_script(script, webElement)\n",
    "    script = \"arguments[0].innerHTML = '<h1>\" + sele_text[highest_probability_index] + \"</h1>'\"\n",
    "    driver.execute_script(script, webElementtxt)\n",
    "    \n",
    "    last_led = LEDS[highest_probability_index]\n",
    "    last_led.on()\n",
    "    return last_led"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Listen to the microphone and process the audio data into spectrograms.\n",
    "    \"\"\"\n",
    "    global audio_buffer\n",
    "    \n",
    "    model = load_model(MODEL_PATH, compile=False)\n",
    "\n",
    "    audio_buffer = np.empty(\n",
    "        (int(REC_SAMPLE_RATE * DURATION),),\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n",
    "    # Create an audio stream and record to the audio buffer.\n",
    "    with InputStream(blocksize=CHUNK_SIZE, samplerate=REC_SAMPLE_RATE, channels=CHANNEL_NB, callback=expand_audio_buffer):\n",
    "        print(\"Start\")\n",
    "\n",
    "        try:\n",
    "            while True: # Use Ctrl+C to trigger a KeyboardInterrupt and exit\n",
    "\n",
    "                if len(audio_buffer) < CHUNK_SIZE:\n",
    "                    continue\n",
    "\n",
    "                prediction = get_prediction(audio_buffer, model)\n",
    "                activate_leds(prediction)\n",
    "\n",
    "                if DEBUG:\n",
    "                    print(format_prediction(prediction))\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "    if DEBUG:\n",
    "        global debug_wav\n",
    "        debug_wav = np.round(debug_wav / np.max(debug_wav) * 32767).astype(np.int16)\n",
    "        write(DEBUG_AUDIO_PATH, REC_SAMPLE_RATE, debug_wav)\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
